<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdn.bootcdn.net/ajax/libs/gl-matrix/2.8.1/gl-matrix-min.js"></script>
  <title>Document</title>
</head>
<body>
  <canvas id="myCanvas" style="border:1px solid red;" width="600" height="400"></canvas>

  <script type="text/javascript">
    /**
     * Using textures in WebGL
     * 
     * 现在我我们已经创建好了一个可以旋转的3d的立方体，记下来是时候使用贴图来代替每个面
     * 的单一的颜色了
     * 
     * 加载纹理
     * 
     * 首先计入加载纹理的代码。现在我们只使用一张单一的纹理贴到立方体的6个面上，但是
     * 同样的方法可以用来加载任意数量的纹理贴图
     * 
     * 注意：值得注意的一点是对纹理的加载同样需要遵循跨域访问规则；也就是说你只能从允许
     * 跨域的网址加载你需要的纹理。
     * 
     * 加载纹理代码如下：
     * 
     * 函数initTextures()首先调用GL createTexture()函数来创建一个GL纹理对象cubeTexture。
     * 为了把图片文件加载到纹理，代码首先创建了一个Image对象然后把需要当作纹理使用的图形文件
     * 加载了进来。当图片加载完成后回调函数handleTextureLoaded()就会执行。
     * 
     * 接下来为了真正的形成纹理，我们通过吧新创建的纹理对象绑定到gl.TEXTURE_2D来让它成为当前
     * 操作纹理。然后通过调用texImage2d()把已经加载的图片图形数据写到纹理
     * 
     * 代码的接下来两行设置了纹理过滤器，过滤器用来控制当图片缩放时像素如何生成如何插值。
     * 在这个例子里，我们对图片放大使用的是线性过滤，而对图片缩小使用的是多级渐进纹理过滤。
     * 接下来我们通过调用generateMipMap()来生成多级渐进纹理，
     * 接着通过给gl.TEXTURE_2D绑定值null来告诉WebGL我们对当前纹理的操作已经结束了。
     * 
     * 但要特别注意的是：这种非2的幂纹理不能用来生成多级渐进纹理，而且不能使用使用纹理重复（
     * 重复纹理寻址等）。
     * 
     * 使用重复纹理寻址的一个例子就是使用一张砖块的纹理来平铺满一面墙壁
     * 
     * 多级渐进纹理和纹理坐标重复可以通过调用texParameteri()来禁用，当然首先你已经通过调用
     * bindTexture()绑定过纹理了。这样虽然已经可以使用非2的幂纹理了，但是你将无法使用多级
     * 渐进纹理，纹理坐标包装，纹理坐标重复，而且无法控制设备如何处理你的纹理。
     * 
     * 数组变量textureCoordinates中定义好了与每个面上的每个顶点一一对应的纹理坐标。
     * 请注意，纹理坐标的取值范围只能从0.0到1.0，所以不论纹理贴图的实际大小是多少，为了
     * 实现纹理映射，我们要使用的纹理坐标之只能规范化到0.0到1.0的范围内。
     * 
     * 绘制具体纹理贴图的立方体
     * 
     * 接下来是对drawScene()函数的更改，为了使整体的代码看起来更整洁，我们去掉了让立方体
     * 位置变化的代码，现在他只会随着时间的变化进行旋转，而为了使用纹理，索要进行的代码更改
     * 确使很少的
     * 
     * 使用下面的代码代替映射颜色到纹理的代码：
     * 
     * gl.activeTexture(gl.TEXTURE0)
     * gl.bindTexture(gl.TEXTURE_2D, cubeTexture)
     * gl.uniform1i(gl.getUniformLocation(shaderProgram, 'uSampler'), 0)
     * 
     * GL最多可同时注册32张纹理
     * gl.TEXTURE0是第一张。我们把我们之前加载的纹理绑定到了第一个寄存器，然后着色器程序
     * 里的采样器uSampler就会完成它的功能；使用纹理
     * 
     * 关于跨域纹理
     * 
     * 加载WebGL纹理应该也可以说是跨域访问控制里的一个话题。为了再我们的显示内容
     * 里使用其他域名的纹理图片，允许跨域访问也是要考虑的。
     * 
     * 
     **/ 


    var canvas = document.getElementById('myCanvas')
    //初始化WebGL上下文
    var gl = canvas.getContext('webgl')
    
    //初始化着色器程序，让WebGL知道如何绘制我们的数据
    function initShaderProgram(gl, vsSource, fsSource) {
      const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vsSource)
      const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fsSource);
      
      //创建着色器程序
      const shaderProgram = gl.createProgram();
      gl.attachShader(shaderProgram, vertexShader)
      gl.attachShader(shaderProgram, fragmentShader)
      gl.linkProgram(shaderProgram)

      //创建失败，alert
      if(!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
        alert('Unable to initialize the shader program: ' + gl.getProgramInfoLog(shaderProgram));
        return null;
      }

      return shaderProgram;
    }

    //创建指定类型的着色器，上传source源码并编译
    function loadShader(gl, type, source) {
      const shader = gl.createShader(type);

      //send the source to the shader object
      gl.shaderSource(shader, source)

      //compile the shader program
      gl.compileShader(shader)

      //see if it compiled successfully
      if(!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        alert('An error occurred compiling the shaders: ' + gl.getShaderInfoLog(shader));
        gl.deleteShader(shader)
        return null;
      }

      return shader;
    }

    const vsSource = `
      attribute vec4 aVertexPosition;
      attribute vec2 aTextureCoord;
    
      uniform mat4 uModelViewMatrix;
      uniform mat4 uProjectionMatrix;

      varying highp vec2 vTextureCoord;
    
      void main() {
        gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
        vTextureCoord = aTextureCoord;
      }
    `;

    const fsSource = `
      varying highp vec2 vTextureCoord;

      uniform sampler2D uSampler;

      void main() {
        gl_FragColor = texture2D(uSampler, vTextureCoord);
      }
    `;

    const shaderProgram = initShaderProgram(gl, vsSource, fsSource)

    const programInfo = {
      program: shaderProgram,
      attribLocations: {
        vertexPosition: gl.getAttribLocation(shaderProgram, 'aVertexPosition'),
        textureCoord: gl.getAttribLocation(shaderProgram, 'aTextureCoord'),
      },
      uniformLocations: {
        projectionMatrix: gl.getUniformLocation(shaderProgram, 'uProjectionMatrix'),
        modelViewMatrix: gl.getUniformLocation(shaderProgram, 'uModelViewMatrix'),
        uSampler: gl.getUniformLocation(shaderProgram, 'uSampler'),
      }
    }

    function initBuffers(gl) {
      var vertices = [
        // Front face
        -1.0, -1.0,  1.0,
        1.0, -1.0,  1.0,
        1.0,  1.0,  1.0,
        -1.0,  1.0,  1.0,

        // Back face
        -1.0, -1.0, -1.0,
        -1.0,  1.0, -1.0,
        1.0,  1.0, -1.0,
        1.0, -1.0, -1.0,

        // Top face
        -1.0,  1.0, -1.0,
        -1.0,  1.0,  1.0,
        1.0,  1.0,  1.0,
        1.0,  1.0, -1.0,

        // Bottom face
        -1.0, -1.0, -1.0,
        1.0, -1.0, -1.0,
        1.0, -1.0,  1.0,
        -1.0, -1.0,  1.0,

        // Right face
        1.0, -1.0, -1.0,
        1.0,  1.0, -1.0,
        1.0,  1.0,  1.0,
        1.0, -1.0,  1.0,

        // Left face
        -1.0, -1.0, -1.0,
        -1.0, -1.0,  1.0,
        -1.0,  1.0,  1.0,
        -1.0,  1.0, -1.0
      ];
      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer)
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(vertices), gl.STATIC_DRAW)

      const textureCoordinates = [
        // Front
        0.0,  0.0,
        1.0,  0.0,
        1.0,  1.0,
        0.0,  1.0,
        // Back
        0.0,  0.0,
        1.0,  0.0,
        1.0,  1.0,
        0.0,  1.0,
        // Top
        0.0,  0.0,
        1.0,  0.0,
        1.0,  1.0,
        0.0,  1.0,
        // Bottom
        0.0,  0.0,
        1.0,  0.0,
        1.0,  1.0,
        0.0,  1.0,
        // Right
        0.0,  0.0,
        1.0,  0.0,
        1.0,  1.0,
        0.0,  1.0,
        // Left
        0.0,  0.0,
        1.0,  0.0,
        1.0,  1.0,
        0.0,  1.0,
      ];
      let textureCoordBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, textureCoordBuffer)
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(textureCoordinates), gl.STATIC_DRAW)
      
      var cubeVerticesIndexBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, cubeVerticesIndexBuffer)

      var cubeVertexIndices = [
        0,  1,  2,      0,  2,  3,    // front
        4,  5,  6,      4,  6,  7,    // back
        8,  9,  10,     8,  10, 11,   // top
        12, 13, 14,     12, 14, 15,   // bottom
        16, 17, 18,     16, 18, 19,   // right
        20, 21, 22,     20, 22, 23    // left
      ];

      gl.bufferData(
        gl.ELEMENT_ARRAY_BUFFER, 
        new Uint16Array(cubeVertexIndices), 
        gl.STATIC_DRAW
      );

      return {
        position: positionBuffer,
        textureCoord: textureCoordBuffer,
        indices: cubeVerticesIndexBuffer
      }
    }

    // Here's where we call the routine that builds all the
    // objects we'll be drawing.
    const buffers = initBuffers(gl);
    const texture = loadTexture(gl, 'cubetexture.png')

    var cubeRotation = 0.0;
    var then = 0;

    // Draw the scene repeatedly
    function render(now) {
      now *= 0.001;  // convert to seconds
      const deltaTime = now - then;
      then = now;

      drawScene(gl, programInfo, buffers, texture, deltaTime);

      requestAnimationFrame(render);
    }
    requestAnimationFrame(render);

    // Draw the scene
    //drawScene(gl, programInfo, buffers, deltaTime);

    function drawScene(gl, programInfo, buffers, texture, deltaTime) {
      gl.clearColor(0.0, 0.0, 0.0, 1.0);  // Clear to black, fully opaque
      gl.clearDepth(1.0);                 // Clear everything
      gl.enable(gl.DEPTH_TEST);           // Enable depth testing
      gl.depthFunc(gl.LEQUAL);            // Near things obscure far things

      // Clear the canvas before we start drawing on it.

      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

      // Create a perspective matrix, a special matrix that is
      // used to simulate the distortion of perspective in a camera.
      // Our field of view is 45 degrees, with a width/height
      // ratio that matches the display size of the canvas
      // and we only want to see objects between 0.1 units
      // and 100 units away from the camera.

      const fieldOfView = 45 * Math.PI / 180;   // in radians
      const aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
      const zNear = 0.1;
      const zFar = 100.0;
      const projectionMatrix = mat4.create();

      // note: glmatrix.js always has the first argument
      // as the destination to receive the result.
      mat4.perspective(projectionMatrix,
                      fieldOfView,
                      aspect,
                      zNear,
                      zFar);

      // Set the drawing position to the "identity" point, which is
      // the center of the scene.
      const modelViewMatrix = mat4.create();

      // Now move the drawing position a bit to where we want to
      // start drawing the square.

      mat4.translate(modelViewMatrix,     // destination matrix
                    modelViewMatrix,     // matrix to translate
                    [-0.0, 0.0, -6.0]);  // amount to translate

      mat4.rotate(
        modelViewMatrix,
        modelViewMatrix,
        cubeRotation,
        [0, 0, 1]
      );
      mat4.rotate(
        modelViewMatrix,
        modelViewMatrix,
        cubeRotation * .7,
        [0, 1, 0]
      );

      // Tell WebGL how to pull out the positions from the position
      // buffer into the vertexPosition attribute.
      {
        const numComponents = 3;  // pull out 3 values per iteration
        const type = gl.FLOAT;    // the data in the buffer is 32bit floats
        const normalize = false;  // don't normalize
        const stride = 0;         // how many bytes to get from one set of values to the next
                                  // 0 = use type and numComponents above
        const offset = 0;         // how many bytes inside the buffer to start from
        gl.bindBuffer(gl.ARRAY_BUFFER, buffers.position);
        gl.vertexAttribPointer(
            programInfo.attribLocations.vertexPosition,
            numComponents,
            type,
            normalize,
            stride,
            offset);
        gl.enableVertexAttribArray(
            programInfo.attribLocations.vertexPosition);
      }

      {
        const numComponents = 2;  // pull out 3 values per iteration
        const type = gl.FLOAT;    // the data in the buffer is 32bit floats
        const normalize = false;  // don't normalize
        const stride = 0;         // how many bytes to get from one set of values to the next
                                  // 0 = use type and numComponents above
        const offset = 0;         // how many bytes inside the buffer to start from
        gl.bindBuffer(gl.ARRAY_BUFFER, buffers.textureCoord);
        gl.vertexAttribPointer(
            programInfo.attribLocations.textureCoord,
            numComponents,
            type,
            normalize,
            stride,
            offset);
        gl.enableVertexAttribArray(
            programInfo.attribLocations.textureCoord);
      }

      //Tell WebGL which indices to use to index vertices
      gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffers.indices)

      // Tell WebGL to use our program when drawing

      gl.useProgram(programInfo.program);

      // Set the shader uniforms

      gl.uniformMatrix4fv(
          programInfo.uniformLocations.projectionMatrix,
          false,
          projectionMatrix);
      gl.uniformMatrix4fv(
          programInfo.uniformLocations.modelViewMatrix,
          false,
          modelViewMatrix);

      gl.activeTexture(gl.TEXTURE0)
      gl.bindTexture(gl.TEXTURE_2D, texture)
      gl.uniform1i(programInfo.uniformLocations.uSampler, 0);

      {
        const offset = 0;
        const vertexCount = 36;
        const type = gl.UNSIGNED_SHORT;
        // gl.drawArrays(gl.TRIANGLE_STRIP, offset, vertexCount);
        gl.drawElements(gl.TRIANGLES, vertexCount, type, offset);
      }

      cubeRotation += deltaTime;
    }

    function loadTexture(gl, url) {
      const texture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, texture);

      const level = 0;
      const internalFormat = gl.RGBA;
      const width = 1;
      const height = 1;
      const border = 0;
      const srcFormat = gl.RGBA;
      const srcType = gl.UNSIGNED_BYTE;
      const pixel = new Uint8Array([0, 0, 255, 255]);  
      gl.texImage2D(gl.TEXTURE_2D, level, internalFormat,
                width, height, border, srcFormat, srcType,
                pixel);

      const image = new Image();
      image.onload = function() {
        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.texImage2D(gl.TEXTURE_2D, level, internalFormat, srcFormat, srcType, image);

        if(isPowerOf2(image.width) && isPowerOf2(image.height)) {
          gl.generateMipmap(gl.TEXTURE_2D)
        } else {
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
          gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        }
      }
      image.src = url;

      return texture;
    }

    function isPowerOf2(value) {
      return (value & (value - 1)) == 0;
    }
  </script>
</body>
</html>